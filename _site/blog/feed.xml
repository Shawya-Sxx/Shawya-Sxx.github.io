<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sxx's 513_planet</title>
    <description>I am Shi Xiaoxia.</description>
    <link>http://localhost:4000</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>旁人的毕业季，寝室的离别季，自己的生日季</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;燕燕于飞，下上其音。之子于归，远送于南。瞻望弗及，实劳我心。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;又到了一年的毕业季，校园里满目都是毕业的气息，穿着学士服，硕士服的同学在校园里穿梭，拍下一张张值得珍藏的回忆。还有寝室楼下堆叠的行李。突然觉得自己真的老了，看到这种场景，有一种无法描述的情感涌现，有惆怅，有祝福，有羡慕，有更多。回想起自己本科毕业，也满一周年了。可能一年前的自己还年轻吧，毕业更多的是激动而不是感慨，也没有离别的伤感，于是上午参加完毕业典礼，下午就开始了自己的毕业旅行，那天是2017年6月18日。现在想来，多多少少是有些遗憾的，没有好好地同学校告个别，没有好好地同同学告个别。几天前实验室聚了餐，欢送师兄师姐。实验室一下冷清了许多。感慨时间如流水，马上就会轮到自己，希望那个时候的我能对得起这三年。&lt;/p&gt;

&lt;p&gt;因为琦琦和萱萱的导师允许研二出去实习，于是华丽丽的剩下了我和蕾蕾在学校相依为命。离别前夕，突然讲到大家还没一起去唱歌，于是晚上12点说走就走，校园的长廊下，还有人弹着吉他，还有人唱着离别的歌，还有人跳着舞，他们享受着离别前的狂欢或纪念逝去的大学时光，总之，在那样一个夜，我也跟着醉了。毫无意外，我们在KTV唱了一个通宵，各种笑与狂欢。亲爱的们，一年后再见。感恩遇见你们，标准的北方妹子。
&lt;img src=&quot;/images/2.JPG&quot; alt=&quot;&quot; /&gt; 
  6月26日，我的生日，在各方祝福下，买了个蛋糕，点了自己想吃的，在琦琦的视频中，萱萱和蕾蕾的陪伴下，澍澍的琴声中许完了愿，然后三个人瓜分了蛋糕。临近睡前，又想吃烧烤，于是拉上萱萱和蕾蕾，翻越了学校西南门，出去吃了一顿，第一次翻墙真是不可言喻，三个人都疯了。
  &lt;img src=&quot;/images/2.PNG&quot; alt=&quot;&quot; /&gt; 
  研究生生活相比本科生活，真是简单了很多，偶尔上上课，其他时间就是在宿舍-食堂-实验室，三点一线，日子也就这样不知不觉的过了。研二即将开始，加油！&lt;/p&gt;
</description>
        <pubDate>Fri, 29 Jun 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000//blog/graduate-birthday.html</link>
        <guid isPermaLink="true">http://localhost:4000//blog/graduate-birthday.html</guid>
      </item>
    
      <item>
        <title>基于内容的图像检索简介</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;寂寞是琐碎的东西，但只要一个触点，就可以点燃心里的荒芜。所以我不责怪寂寞，我只能责怪我心底的荒芜。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;背景与意义&quot;&gt;背景与意义&lt;/h2&gt;

&lt;p&gt;近年来，随着社交网络的盛行以及移动互联网的快速发展，智能手机已成为人们日常生活中不可或缺的一部分。智能手机硬件的不断升级，也直接促进了其内置摄像功能的发展，可以说智能手机已改变了人们的拍照方式。对于年轻人来说，已经养成了使用手机随时随地拍摄照片并且分享至社交网络的习惯。&lt;/p&gt;

&lt;p&gt;图像检索的研究可以分为两个大的阶段：基于文本的图像检索(TBIR, Text Based Image Retrieval)以及基于内容的图像检索(CBIR, Content Based Image Retrieval)。&lt;/p&gt;

&lt;p&gt;基于文本的图像检索其核心思路是通过对图像文件采用手工或者自动标注的方式添加描述字段，例如主题，内容标签，来源，作者等信息，然后使用关键字匹配的方式进行检索。但文本与图像间信息量的巨大差异使得关键字描述很难充分的表达图像所包含的内容，且每个人对图像的理解都存在差异，因此在手工添加标注的时候极易受主观因素向导，且这种方式需要耗费大量的人力时间来为图像添加标注，并且图像像素中所包含的视觉信息也没有被充分利用，这是一种信息资源的巨大浪费。&lt;/p&gt;

&lt;p&gt;得益于计算机硬件的发展，基于内容的图像检索方法逐渐受到关注。通过对图像像素信息的分析提取图像特征，再通过特征的后处理，聚合，压缩，编码等操作，最后根据模型生成图像表达用于不同图像之间的相似性度量，完成图像检索任务。
近几年，社会呈现越来越网络化的趋势。人们热衷于相互分享各种见闻，并将大量的旅游照片，生活图片以及各种各样的视频上传至互联网与众人分享。海量数据集的出现将信息时代进一步推进至大数据时代。伴随着大数据时代的到来以及GPU等各种强大的计算设备的发展，神经网络这一曾经陷入低谷的领域再一次步入人们的视野。深度神经网络曾经面临的三个难点：因为网络的高度非线性而导致的有太多局部极值，难以获得一个好的解；早期过小的数据集会导致多层神经网络严重过拟合；计算能力的不足使得无法训练大规模的网络。而2006年，著名学者Geoffrey Hinton在Science上发表的深度学习论文，给出了训练深层网络的新思路。短短十年间，深度学习方法颠覆了自然语言处理，语音识别，计算机视觉等很多领域的算法设计思路，形成了一种以数据驱动，针对特定任务训练一个端对端模型并直接获得最终结果的新模式。而卷积神经网络在图像领域良好的图像表达能力也再一次被发掘并大量使用使用，在计算机视觉领域中的许多复杂问题中获得了惊人的突破。在很多大数据集上卷积神经网络都取得了良好的效果。随着相关理论的不断完善和发展，卷积神经网络将是各种计算机视觉问题中一个不可忽视的解决方案。&lt;/p&gt;

&lt;p&gt;图像检索相关方法的不断完善也促进了相关应用的发展。在电子商务方面，谷歌的Goggles、 阿里巴巴的拍立淘等闪拍购物应用允许用户抓拍上传至服务器端，在服务器端运行图片检索应用从而为用户找到相同或相似的衣服并提供购买店铺的链接；在医疗诊断方面，医生通过检索医学影像库找到多个病人的相似部位，从而可以协助医生做病情的诊断；行人检测，人脸识别，目标跟踪等领域都已经出现了成熟的应用，在有些领域机器的准确率甚至已经超过人类。在旅游领域中，我们注意到用户在旅行的过程中，往往会产生大量的照片数据以及地理位置信息数据，这些数据中都蕴含着大量的景点相关信息。在传统的旅游应用中，虽然拥有大量用户上传的图片数据，却没有充分的利用这些图像信息，而是仅仅起到了帮助用户存储照片的作用。在景点识别方面，传统的旅游应用还是基于文字标签的检索方式。然而，文本检索有需要用户拥有先验知识以及关键字重复率高等问题。而通过图像检索及识别的算法用户只需拿出手机拍摄一张照片就可以获得想要的信息。基于内容的图像检索技术已经深入到了许许多多的领域，为人们的生活生产提供了极大的便利。&lt;/p&gt;

&lt;h2 id=&quot;国内外研究现状&quot;&gt;国内外研究现状&lt;/h2&gt;

&lt;p&gt;首先，在图像特征表示方法上获得了大量的研究进展。早期研究中主要是利用颜色特征，纹理特征等全局特征进行图像匹配。后来更细致的局部特征描述子逐步出现，例如经典的SIFT（ Scale Invariant Feature Transform）特征，以及基于SIFT特征的各种变种，例如PCA-SIFT，SURF，RootSIFT等。在获得拥有良好视觉表达能力的特征后，研究者又提出了将局部特征聚合为图像全局表达的方法，例如视觉词汇包模型BoW（Bag of visual Words）。BoW直方图的生成是通过对于词汇码本中的视觉词汇按序标号，然后记录每个视觉词汇在查询图中的出现频次。因此BoW直方图的纬度与视觉词汇码本的大小相同。因为通常词汇码书的大小在百万数量级，因此BoW直方图维度相当大，这会给检索过程带来相当大计算复杂度。为进一步提高检索精度与速度，Lepetit提出使用近似K均值（Approximate k-means），通过构建K-D树的方式提高聚类及量化速度；或通过分层K均值方式构建分级聚类中心。还有一些研究通过软量化的方式提升检索性能。在获得初步检索结果后，许多研究人员又进一步提出了检索输入扩展，多查询图搜索以及基于几何约束的空间重排算法，在原本的检索结果上再一次提高了检索系统的整体性能。Zhao等人通过引入显著区域提取的方法，利用显著区域进行检索可以进一步提高检索效果。
2008年Hays和Efros等人在IM2GPS中提出了一种估计图像地理位置的方法，其思想是使用图像的低级全局特征，在大规模图像数据集中寻找近邻图像，之后使用聚类的方式对输入图像的地理位置进行估计。具体流程为，首先对输入图像提取各类全局特征，然后计算输入图像与图像库中所有图像的聚类，最后根据相似度选取K个最相似的图像，最后使用聚类方法寻找相似图像的位置中心来估计图像的GPS位置。之后，Li等人提出了通过使用 BoW 模型，利用训练一对多级联 SVM 分类器的方法进行大规模图像位置估计。在文章中他们发现通过添加文字描述，如文本tag，分类性能可以得到一定的改善。而对于没有标签描述的图像，则完全使用图像内容进行位置估计。这种方法拥有较高的时间复杂度，需要消耗大量时间以及计算资源来训练模型，同时模型的扩展性也较差。当数据集改变时，需要重新进行SVM 模型训练。Torii等人提出通过视角计算，通过寻找相同视角的图片，获得更精确的位置估计结果。Li等人提出通过使用图像结合POI提取的方式进行GPS估计. Quack 等人提出了一种基于局部特征匹配的估计图像地理位置的方法。为了减小初始位置估计的范围，方法要求用户要手动选取一个粗略的估计范围，然后在用户圈定的范围内进行估计。这种方法在一定程度上提高了检索效率，但也存在一些问题，一是要求用户对图像的可能位置要有先验知识，然而很多情况下用户可能完全无法给出图像可能的初始范围。另外，检索结果的准确率过于依赖用户划定的初始位置，若无法保证这个初始范围的正确性，将严重影响位置估计的结果。Vishal等人则提出利用图像结合GPS sensor的方式，以改善GPS信号噪声过大时造成位置偏差的问题。
2012年，由Hinton及Alex提出的深度卷积神经网络在ImageNet竞赛中取得了惊人的效果，深度学习以及卷积神经网络有重新回到科研人员的视野中。早期，LeCun提出的LeNet在Mnist手写数据集中取得了不错的识别效果。但在后续对于深度神经网络的探索中，人们发现神经网络有容易陷入局部最优，数据集过小而造成网络过拟合，对于计算硬件性能要求过高等在当时看来难以解决的问题。而随着GPU计算能力的飞速发展以及大规模图像数据集的出现，深度卷积神经网络又迎来了新的春天。
AlexNet是由卷积层，池化层以及全连接层组合而成，最后使用softmax层表达图片分类至某一类别的概率。网络的训练是基于误差反向传播的思想，通过梯度下降方法优化整个网络的参数。卷积神经网络相较于传统的前馈神经网络，由于权值共享及局部感受野等概念的提出，在卷积层大大减少了参数数量。为了减少全连接层过拟合的现象，文章也引入了新的正则化方法dropout。AlexNet在测试数据集上得到了top-1误差率37.5%，以及top-5误差率17.0%的结果，这比之前最顶尖的结果还要好的多。
2014年，牛津大学visual geometry group（VGG）提出了VGGNet并探讨了网络深度对于网络的重要性，并建立了最多19层的网络。相较于AlexNet，VGG做出了以下改进：使用了更小的卷积核尺寸以及间隔，并加深网络深度，例如使用3个3x3的卷积核代替7x7的卷积核；在多尺度上训练和测试图片；去掉了LRN层。VGGNet在ILSVRC上取得了定位第一，分类第二的结果。同年，Google在文章《Going Deeper with Convolutinos》中也提出了与VGGNet类似的思想，他们受到Network in Network的启发，提出Inception网络结构。在Inception结构中使用了很多1x1的卷积核，此举的主要目的是降低维度，以此去除部分因网络层数过深造成的运算瓶颈。文章中提出，因为低层卷积层对应着图像的某个区域，使用1x1的卷积核依然对应这个区域，使用3x3的卷积核则可以对应更大的区域。通过不同大小的卷积核获取图像特征再通过Filter concatenation层将卷积结果连接起来，以获得更具表现力的图像表达，同时也防止了层数增多带来的的计算资源的爆炸性需求，从而使网络的广度和深度均可扩大。在图像检索，目标识别，场景识别等领域，卷积神经网络也获得了充分的利用。一些研究人员尝试使用基于大规模数据集预训练的CNN网络模型获得图像特征，这些方法通常会选择网络固定一层或几层的激励拼接出能表达图像内容的全局特征，并通过这些特征进行图像内容匹配并进一步进行位置估计。Razavian等人提出使用现成的网络预训练模型提取图像特征，例如AlexNet的最后一个全连接层作为图像特征，并通过图像检索的方式确定图像位置。Gong等人提出在网络中引入空间信息以获得更好的图像聚合表达；在场景识别数据集SUN数据集上，Sermanet和LeCun等人提出的CNN模型Overfeat获得了良好的性能，比传统基于GIST及SIFT特征的地标识别系统中性能最好的方法还要高出很多，同时Overfeat网络在Places数据集上也取得了巨大的提升。&lt;/p&gt;

</description>
        <pubDate>Sun, 15 Apr 2018 00:00:00 +0800</pubDate>
        <link>http://localhost:4000//blog/image-retrieval-introduction.html</link>
        <guid isPermaLink="true">http://localhost:4000//blog/image-retrieval-introduction.html</guid>
      </item>
    
  </channel>
</rss>
